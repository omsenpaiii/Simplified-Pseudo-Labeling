@INPROCEEDINGS{ican,
	author={Zhang, Weichen and Ouyang, Wanli and Li, Wen and Xu, Dong},
	booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
	title={Collaborative and Adversarial Network for Unsupervised Domain Adaptation}, 
	year={2018},
	volume={},
	number={},
	pages={3801-3809},
	keywords={Training;Collaboration;Feature extraction;Adaptation models;Visualization;Task analysis;Computer vision},
	doi={10.1109/CVPR.2018.00400}
}

@article{pseudo-label-original,
	author = {Lee, Dong-Hyun},
	year = {2013},
	month = {07},
	pages = {},
	title = {Pseudo-Label : The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks},
	journal = {ICML 2013 Workshop : Challenges in Representation Learning (WREPL)}
}

@inproceedings{entropy-regularization,
	title={Semi-supervised Learning by Entropy Minimization},
	author={Yves Grandvalet and Yoshua Bengio},
	booktitle={Conf{\'e}rence francophone sur l'apprentissage automatique},
	year={2004},
	url={https://api.semanticscholar.org/CorpusID:7890982}
}

@inproceedings{pseudo-label-evaluation,
	title	= {Realistic Evaluation of Semi-Supervised Learning Algorithms},
	author	= {Avital Oliver and Augustus Odena and Colin Raffel and Ekin Dogus Cubuk and Ian Goodfellow},
	year	= {2018},
	URL	= {https://arxiv.org/pdf/1804.09170.pdf}
}

@article{good-practices,
	title={A formal approach to good practices in Pseudo-Labeling for Unsupervised Domain Adaptive Re-Identification}, 
	author={Fabian Dubourvieux and Romaric Audigier and Angélique Loesch and Samia Ainouz and Stéphane Canu},
	year={2022},
	eprint={2112.12887},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{model-survey,
	title={A Survey of Unsupervised Domain Adaptation for Visual Recognition}, 
	author={Youshan Zhang},
	year={2021},
	eprint={2112.06745},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{resnet,
	title={Deep Residual Learning for Image Recognition}, 
	author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	year={2015},
	eprint={1512.03385},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@INPROCEEDINGS{imagenet,
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
	booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
	title={ImageNet: A large-scale hierarchical image database}, 
	year={2009},
	volume={},
	number={},
	pages={248-255},
	keywords={Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
	doi={10.1109/CVPR.2009.5206848}
}

@InProceedings{modern-office,
	author    = {Ringwald, Tobias and Stiefelhagen, Rainer},
	title     = {Adaptiope: A Modern Benchmark for Unsupervised Domain Adaptation},
	booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
	month     = {January},
	year      = {2021},
	pages     = {101-110}
}

@InProceedings{office,
	author="Saenko, Kate
	and Kulis, Brian
	and Fritz, Mario
	and Darrell, Trevor",
	editor="Daniilidis, Kostas
	and Maragos, Petros
	and Paragios, Nikos",
	title="Adapting Visual Category Models to New Domains",
	booktitle="Computer Vision -- ECCV 2010",
	year="2010",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="213--226",
	abstract="Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions.",
	isbn="978-3-642-15561-1"
}

@ARTICLE{mnist,
	author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	journal={Proceedings of the IEEE}, 
	title={Gradient-based learning applied to document recognition}, 
	year={1998},
	volume={86},
	number={11},
	pages={2278-2324},
	abstract={Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
	doi={10.1109/5.726791},
	ISSN={1558-2256},
	month={Nov},}

@misc{mnist-m,
	title={Domain-Adversarial Training of Neural Networks}, 
	author={Yaroslav Ganin and Evgeniya Ustinova and Hana Ajakan and Pascal Germain and Hugo Larochelle and François Laviolette and Mario Marchand and Victor Lempitsky},
	year={2016},
	eprint={1505.07818},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@misc{three-models,
	title={Asymmetric Tri-training for Unsupervised Domain Adaptation}, 
	author={Kuniaki Saito and Yoshitaka Ushiku and Tatsuya Harada},
	year={2017},
	eprint={1702.08400},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@misc{coral,
	title={Deep CORAL: Correlation Alignment for Deep Domain Adaptation}, 
	author={Baochen Sun and Kate Saenko},
	year={2016},
	eprint={1607.01719},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}